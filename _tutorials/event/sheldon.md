---
layout: post
title: "S.H.E.L.D.O.N. Tutorial"
categories:
  - event
---

**TOOLS:**

* Soldering Iron

* Laptop

* Visual Studio / MATLAB / Any IDE with an Image Processing Library	

* AVR programming software / Arduino IDE

**MATERIALS**:

* 2 Wheels

* 1 Castor Wheel

* Metal Chassis

* 2 DC motors

* 1 Development Board

* 1 Microcontroller (ATmega 16/32/328)

* 1 Programmer (ISP/Arduino)

* Motor Driver (L293D)

* 1 LED

* Relimates

* Bluetooth Communication module/ USB-UART/ Xbee

**PROBLEM STATEMENT:**

Build an image processing robot capable of detecting characters, using an overhead camera and traversing them such that the equation generated by the traversal fulfills a certain condition.

We’ll split the Problem Statement into Modules.

In this DIY , we’ll step by step discuss each module. The first thing to do is to make a mobile robot capable of moving according to instructions received from the laptop.

**PART 1 - A REMOTE CONTROLLED ROBOT:**

**LOCOMOTION**

The robot can be made to move by using a differential drive as the base. With independent motors for the left and right sides of the base, differential drives allow the robot to move in all directions and turn as well. How the motors will rotate will be determined by the voltage supplied to the motor by the motor driver circuit, which in turn will depend on the instructions sent to the motor driver by the microcontrollers. For more details on differential drives, please check [here](http://robotix.in/tutorials/category/mechanical/drivemechtut).

![]({{ site.baseurl }}/img/tutorial/event/sheldon/image_0.jpg){:class="img-responsive"}

Fig: The schematics of a differential drive

![]({{ site.baseurl }}/img/tutorial/event/sheldon/image_1.png){:class="img-responsive"}

Fig: An actual differential drive

**MICROCONTROLLER**

Conceived to be the brain of the robot, the microcontroller is the device that allows us to control the robot and make it autonomous. By pre-programming it, we can make it give different outputs based on different inputs and instructions received, and thereby the robot acts accordingly. For a more elaborate understanding of the working of an AVR microcontroller, please visit [here](http://www.robotix.in/tutorials/category/avr/avrprog). Essentially you only need to program the microcontroller on your robot, to move in a particular direction, based on the character received by it from the laptop. 

![]({{ site.baseurl }}/img/tutorial/event/sheldon/image_2.jpg){:class="img-responsive"}

Fig: The development board for the microcontroller from Robokits

The code to be burnt on Arduino is as follows :

<script src="https://gist.github.com/sourishg/3e23d43b47056eddd794.js"></script>

**PART 2 – COMPUTER VISION**

Before proceeding with this module, we would request you to go through the set of general[ tutorials](http://www.robotix.in/tutorials) for computer vision, for both MATLAB and OpenCV, also found on our website. It is quite extensive, and we will assume that a working knowledge, as put forward there, is in the grasp of the reader of this tutorial.

**Detecting Contours**

We need to first scan the characters present in the arena using an overhead camera.For that we would need to distinguish them separately as images containing only each one of them as single characters.We will be using [contours](http://docs.opencv.org/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.html) for the same.Contours are basically an outline representing or bounding the shape or form of something.You can learn about how to find contours and draw contours over [here](http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html) .

![]({{ site.baseurl }}/img/tutorial/event/sheldon/image_3.png){:class="img-responsive"}

Note that during the run your image would also contain the robot and marker , start and end zones and noise.Hence you cannot directly feed this image for finding contours.You will need to remove noise by [thresholding](http://docs.opencv.org/2.4.10/doc/tutorials/imgproc/threshold/threshold.html).

Also note that the contours might not be perfect rectangles.Use [ApproxPloyDp](http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html) for the same.

**Predicting Characters Using OCR**

Now given that you have n contours where n are the number of characters you will have to process them so that they return these characters as strings and their positions.A standard way to do it is using [Tesseract - OCR](http://opencv-code.com/tutorials/how-to-integrate-tesseract-ocr-and-opencv/) .It will return you a string for every character recognition.Also positions of the contours can fairly estimated by finding the midpoint of the largest rectangle encompassing the contour.

**Finding a valid expression**

Now given that you have all the characters present in the arena.Design an algorithm that would return you a valid mathematical expression.The mathematical expression among these which satisfies the condition stated before the run is your unique expression.Form a que of the characters you need to visit according to this expression.This que would contain the co-ordinates of the characters and the co-ordinates of the end zone to terminate the run.This que would essentially tell the robot its complete route.

**Tracking the Position of the Robot**

Throughout your run you will require to track the position of the robot.A marker for the same will be provided.The marker will consist of two squares with different colours.RGB values of the colours will be provided.First we need to scan the input image to get all the points whose colour is roughly the same as the colour of square 1/Head.The centre of all these points is the centre of the Head.Similarly we can find the centre of the Tail.The geometric midpoint of these centre can be fairly estimated as the Position of the Robot.

![]({{ site.baseurl }}/img/tutorial/event/sheldon/image_4.png){:class="img-responsive"}

**Locomotion of the Robot**

Now that we know the position of the bot and the position of every subsequent character according to the queue we need to send commands to the robot so that it moves to that particular position.Since all the readings are not accurate with the help of overhead camera we just need to move the robot so that its distance with respect to the subsequent position is less than a certain threshold.
